{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **GRUPO 1** - Trabajo Práctico Nuestras Caras"
      ],
      "metadata": {
        "id": "1kcpECpf1oMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparar el entorno en Google Colab**"
      ],
      "metadata": {
        "id": "vjLYBe6H0PmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se configura el entorno de trabajo para desarrollar el proyecto en Google Colab. Se monta Google Drive para acceder a archivos almacenados, se definen rutas base y se crean carpetas necesarias para guardar resultados, modelos o salidas del entrenamiento."
      ],
      "metadata": {
        "id": "9Wub-z_GeQa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conexion al Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_DJDxsR3qh5",
        "outputId": "8e4d6fc6-8774-46f5-a060-22f53a4d5a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cargar las librerias que vamos a utilizar**"
      ],
      "metadata": {
        "id": "8C8HY96BefY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan las librerías requeridas para el análisis, incluyendo herramientas para manipulación y visualización de datos, procesamiento de imágenes, reducción de dimensionalidad y evaluación de modelos. Esta etapa garantiza que el entorno cuente con todas las funcionalidades necesarias antes de iniciar el procesamiento."
      ],
      "metadata": {
        "id": "jih2JVx1ea5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instalo  itables solo si no esta instalado\n",
        "!pip show itables >/dev/null || pip install itables"
      ],
      "metadata": {
        "id": "y2X7rl9jUe_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8feb153c-8454-43cd-b4b0-be8acddb761a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: itables\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting itables\n",
            "  Downloading itables-2.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from itables) (7.34.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from itables) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from itables) (2.2.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->itables) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->itables)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->itables) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->itables) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->itables) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->itables) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->itables) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->itables) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->itables) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->itables) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->itables) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->itables) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->itables) (2025.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->itables) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->itables) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->itables) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->itables) (1.17.0)\n",
            "Downloading itables-2.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, itables\n",
            "Successfully installed itables-2.3.0 jedi-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from typing import List, Tuple, Dict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# PROYECTO_DIR = \"/content/drive/MyDrive/DMA_Eigenfaces\"\n",
        "# SRC_DIR = os.path.join(PROYECTO_DIR, \"src\")\n",
        "# MODELOS_DIR = os.path.join(PROYECTO_DIR, \"modelos\")\n",
        "\n",
        "#sys.path.append(SRC_DIR)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/src/procesar_imagenes.py\n",
        "!wget https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/src/multiperceptron.py\n",
        "\n",
        "from procesar_imagenes import detectar_cara_dnn, cargar_face_detector, procesar_y_crear_dataset\n",
        "from multiperceptron import multiperceptron\n"
      ],
      "metadata": {
        "id": "ZLjB1-bhceBZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "81c9b878-3881-468d-f71a-ac878c540357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-05 04:19:33--  https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/src/procesar_imagenes.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5787 (5.7K) [text/plain]\n",
            "Saving to: ‘procesar_imagenes.py’\n",
            "\n",
            "\rprocesar_imagenes.p   0%[                    ]       0  --.-KB/s               \rprocesar_imagenes.p 100%[===================>]   5.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-05 04:19:33 (57.2 MB/s) - ‘procesar_imagenes.py’ saved [5787/5787]\n",
            "\n",
            "--2025-05-05 04:19:33--  https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/src/multiperceptron.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13808 (13K) [text/plain]\n",
            "Saving to: ‘multiperceptron.py’\n",
            "\n",
            "multiperceptron.py  100%[===================>]  13.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-05 04:19:33 (89.2 MB/s) - ‘multiperceptron.py’ saved [13808/13808]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script>\n",
              "    let is_dark_theme = function () {\n",
              "        // Jupyter Lab\n",
              "        if ('jpThemeLight' in document.body.dataset)\n",
              "            return (document.body.dataset.jpThemeLight === \"false\");\n",
              "\n",
              "        // VS Code\n",
              "        if ('vscodeThemeKind' in document.body.dataset)\n",
              "            return document.body.dataset.vscodeThemeKind.includes('dark');\n",
              "\n",
              "        // Jupyter Book\n",
              "        if ('theme' in document.documentElement.dataset)\n",
              "            return document.documentElement.dataset.theme.includes('dark');\n",
              "\n",
              "        // Default\n",
              "        return window.matchMedia('(prefers-color-scheme: dark)').matches;\n",
              "    }\n",
              "\n",
              "    if (is_dark_theme()) {\n",
              "        document.documentElement.classList.add('dark');\n",
              "    }\n",
              "    else {\n",
              "        document.documentElement.classList.remove('dark');\n",
              "    }\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Crear directorio para cargar las imágenes**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ei6PpQuGrRZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar las fotos nuevas, se creara una carpeta en el entorno de ejecución de colab en la que se podrán arrastrar o subir las imagenes."
      ],
      "metadata": {
        "id": "93h_xlPArXcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_fotos = \"/content/fotos_nuevas\"\n",
        "\n",
        "os.makedirs(ruta_fotos, exist_ok=True)"
      ],
      "metadata": {
        "id": "Hkj6uk1crsbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Función para procesar imágenes nuevas**"
      ],
      "metadata": {
        "id": "DyP1tyuiOZpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def procesar_imagenes_nuevas(\n",
        "    input_folder: str,\n",
        "    net: cv2.dnn_Net,\n",
        "    img_size: Tuple[int, int] = (64, 64),\n",
        "    confidence_threshold: float = 0.3\n",
        ") -> pl.DataFrame:\n",
        "    \"\"\"\n",
        "    Procesa imágenes nuevas no etiquetadas: detecta la cara, recorta, convierte a gris, resizea,\n",
        "    y arma un DataFrame compatible con la red neuronal entrenada.\n",
        "\n",
        "    Returns:\n",
        "        Polars DataFrame con columnas: 'imagen' (array aplanado) y 'filename' (nombre de archivo)\n",
        "    \"\"\"\n",
        "    imagenes = []\n",
        "    nombres = []\n",
        "\n",
        "    for file in sorted(os.listdir(input_folder)):\n",
        "        if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            continue\n",
        "\n",
        "        path = os.path.join(input_folder, file)\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        box = detectar_cara_dnn(img, net, confidence_threshold)\n",
        "        if box is not None:\n",
        "            x1, y1, x2, y2 = box\n",
        "\n",
        "            # Añadir margen\n",
        "            margin_ratio = 0.2\n",
        "            bw, bh = x2 - x1, y2 - y1\n",
        "            x1 = max(0, x1 - int(bw * margin_ratio))\n",
        "            y1 = max(0, y1 - int(bh * margin_ratio))\n",
        "            x2 = min(img.shape[1], x2 + int(bw * margin_ratio))\n",
        "            y2 = min(img.shape[0], y2 + int(bh * margin_ratio))\n",
        "\n",
        "            face_crop = img[y1:y2, x1:x2]\n",
        "            face_crop = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)\n",
        "            face_crop = cv2.resize(face_crop, img_size)\n",
        "            imagenes.append(face_crop.flatten())\n",
        "            nombres.append(file)\n",
        "\n",
        "    df = pl.DataFrame({\n",
        "        \"filename\": nombres,\n",
        "        **{f\"x{i+1}\": [img[i] for img in imagenes] for i in range(img_size[0] * img_size[1])}\n",
        "    })\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "gTZFbAkZOeGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Función para graficar las fotos originales con la etiqueta asignada por el modelo**\n"
      ],
      "metadata": {
        "id": "cYM8nj_glwRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mostrar_predicciones_con_imagenes(input_folder, df_resultado, columnas=5):\n",
        "    filas = (len(df_resultado) + columnas - 1) // columnas\n",
        "    plt.figure(figsize=(3 * columnas, 3.5 * filas))\n",
        "\n",
        "    for i, row in enumerate(df_resultado.iter_rows(named=True)):\n",
        "        filepath = os.path.join(input_folder, row[\"filename\"])\n",
        "        img = cv2.imread(filepath)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.subplot(filas, columnas, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'{row[\"pred_final\"]}\\n({row[\"confianza\"]:.2f})', fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_Ty8YMT1Hu5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cargar objetos scaler e ISOMAP**\n"
      ],
      "metadata": {
        "id": "1-6KQJaYEB_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar el objeto ISOMAP utilizado para la reducción de dimensiones en el dataset original.\n",
        "\n",
        "Descargamos los archivos scaler.pkl e isomap_9_20.pkl en una carpeta llamada modelos, ubicada en el entorno temporal de ejecución de Colab, para luego cargarlos y reutilizarlos en el preprocesamiento de nuevas imágenes."
      ],
      "metadata": {
        "id": "Fb1yQsn4tYOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir carpeta de modelos\n",
        "MODELOS_DIR = \"/content/modelos\"\n",
        "os.makedirs(MODELOS_DIR, exist_ok=True)\n",
        "\n",
        "# Descargar archivos directamente a la carpeta\n",
        "!wget -P $MODELOS_DIR https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/modelos/scaler.pkl\n",
        "!wget -P $MODELOS_DIR https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/modelos/isomap_9_20.pkl\n",
        "\n",
        "# Cargar objetos\n",
        "with open(os.path.join(MODELOS_DIR, \"scaler.pkl\"), \"rb\") as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(MODELOS_DIR, \"isomap_9_20.pkl\"), \"rb\") as f:\n",
        "    isomap = pickle.load(f)"
      ],
      "metadata": {
        "id": "hCvlAMMqEAS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd6171df-cec8-4ccf-c806-a09a1b924837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-05 04:31:42--  https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/modelos/scaler.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98776 (96K) [application/octet-stream]\n",
            "Saving to: ‘/content/modelos/scaler.pkl’\n",
            "\n",
            "\rscaler.pkl            0%[                    ]       0  --.-KB/s               \rscaler.pkl          100%[===================>]  96.46K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-05-05 04:31:42 (36.8 MB/s) - ‘/content/modelos/scaler.pkl’ saved [98776/98776]\n",
            "\n",
            "--2025-05-05 04:31:42--  https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/modelos/isomap_9_20.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19962819 (19M) [application/octet-stream]\n",
            "Saving to: ‘/content/modelos/isomap_9_20.pkl’\n",
            "\n",
            "isomap_9_20.pkl     100%[===================>]  19.04M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-05-05 04:31:43 (301 MB/s) - ‘/content/modelos/isomap_9_20.pkl’ saved [19962819/19962819]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Descarga de la red entrenda**"
      ],
      "metadata": {
        "id": "KzGuM16Ny53r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar e inicializar el multiperceptron\n",
        "\n",
        "!wget -P $MODELOS_DIR https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/modelos/red.pkl\n",
        "\n",
        "# Cargar la red\n",
        "with open(os.path.join(MODELOS_DIR, \"red.pkl\"), \"rb\") as f:\n",
        "    red = pickle.load(f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA1ZGltaGzlm",
        "outputId": "d4b60741-ded0-476b-809b-f8f219eb2b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-05 04:40:05--  https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/modelos/red.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14966 (15K) [application/octet-stream]\n",
            "Saving to: ‘/content/modelos/red.pkl.5’\n",
            "\n",
            "\rred.pkl.5             0%[                    ]       0  --.-KB/s               \rred.pkl.5           100%[===================>]  14.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-05 04:40:05 (125 MB/s) - ‘/content/modelos/red.pkl.5’ saved [14966/14966]\n",
            "\n",
            "drive\t      modelos\t\t  procesar_imagenes.py\tsample_data\n",
            "fotos_nuevas  multiperceptron.py  __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inicializamos la red neuronal y cargamos el modelo ya entrado**"
      ],
      "metadata": {
        "id": "kwUz2WvTuRF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inicializacion de la red\n",
        "mp = multiperceptron()\n",
        "mp.cargar_modelo((MODELOS_DIR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCW_dmSXufid",
        "outputId": "339742f3-9187-470a-c65e-acf99aa1b67f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1185, np.float64(5.988987418983208e-06), np.float64(0.0))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Carga del modelo DNN para detección de rostros y procesamiento de las nuevas imagenes**"
      ],
      "metadata": {
        "id": "76GO9pSdzJLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = cargar_face_detector()\n",
        "\n",
        "df_nuevas = procesar_imagenes_nuevas(ruta_fotos, net)"
      ],
      "metadata": {
        "id": "YGiPwBWPFPkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creación del dataframe que se utilizará en la red neuronal**"
      ],
      "metadata": {
        "id": "vcozbDQgzjsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Convertir imágenes nuevas a matriz\n",
        "X_nuevas = np.array(df_nuevas.select([f\"x{i+1}\" for i in range(64*64)]))\n",
        "\n",
        "# 2. Escalar con el scaler que guardaste\n",
        "X_nuevas_scaled = scaler.transform(X_nuevas)\n",
        "\n",
        "# 3. Aplicar ISOMAP\n",
        "X_nuevas_iso = isomap.transform(X_nuevas_scaled)\n",
        "\n",
        "# 4. Convertir a DataFrame\n",
        "df_nuevas_reducidas = pl.DataFrame({\n",
        "    **{f\"x{i+1}\": X_nuevas_iso[:, i] for i in range(X_nuevas_iso.shape[1])}\n",
        "})"
      ],
      "metadata": {
        "id": "EGxp01r9DjVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Añadimos una columna y con valores \"?\" como marcador para indicar que estas imágenes nuevas aún no tienen clase asignada. Ya que la red toma el dataframe con la clase y."
      ],
      "metadata": {
        "id": "m83tfLSa0C56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nuevas_reducidas = df_nuevas_reducidas.with_columns(\n",
        "    pl.Series(\"y\", [\"?\"] * df_nuevas_reducidas.height)\n",
        ")"
      ],
      "metadata": {
        "id": "mUiHjh7BF4MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Predicción sobre las nuevas fotos**"
      ],
      "metadata": {
        "id": "p54L9N_j0NrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predecir\n",
        "y_pred, y_raw, _ = mp.predecir(df_nuevas_reducidas, campos=[f\"x{i+1}\" for i in range(X_nuevas_iso.shape[1])], clase=\"y\")\n"
      ],
      "metadata": {
        "id": "8IHTohn6DBHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Filtrado por confianza para detectar intrusos**"
      ],
      "metadata": {
        "id": "_h3c62rU0u6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se calcula la confianza del modelo en cada predicción y se aplica un umbral (0.6).\n",
        "Si la confianza es baja, la imagen se clasifica como “intruso”.\n",
        "Se arma un DataFrame final con el nombre del archivo, la predicción original, la confianza y la predicción ajustada."
      ],
      "metadata": {
        "id": "swzBv9J51QOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculás la confianza\n",
        "confianza_max = [max(vec) for vec in y_raw]\n",
        "\n",
        "# Aplicás el umbral para detectar intrusos\n",
        "umbral = 0.6\n",
        "pred_final = [\"intruso\" if c < umbral else p for c, p in zip(confianza_max, y_pred)]\n",
        "\n",
        "# Armás el DataFrame de resultados\n",
        "df_resultado = pl.DataFrame({\n",
        "    \"filename\": df_nuevas[\"filename\"],\n",
        "    \"pred\": y_pred,\n",
        "    \"confianza\": confianza_max,\n",
        "    \"pred_final\": pred_final\n",
        "})"
      ],
      "metadata": {
        "id": "b3UEn_owFtdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostrar_predicciones_con_imagenes(ruta_fotos, df_resultado)"
      ],
      "metadata": {
        "id": "jAOPXVPmH_10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}