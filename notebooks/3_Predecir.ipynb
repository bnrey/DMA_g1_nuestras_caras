{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **GRUPO 1** - Trabajo Práctico Nuestras Caras"
      ],
      "metadata": {
        "id": "1kcpECpf1oMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparar el entorno en Google Colab**"
      ],
      "metadata": {
        "id": "vjLYBe6H0PmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se configura el entorno de trabajo para desarrollar el proyecto en Google Colab. Se monta Google Drive para acceder a archivos almacenados, se definen rutas base y se crean carpetas necesarias para guardar resultados, modelos o salidas del entrenamiento."
      ],
      "metadata": {
        "id": "9Wub-z_GeQa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conexion al Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_DJDxsR3qh5",
        "outputId": "f2355db3-8199-4495-d9e7-eb99e2057d01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cargar las librerias que vamos a utilizar**"
      ],
      "metadata": {
        "id": "8C8HY96BefY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan las librerías requeridas para el análisis, incluyendo herramientas para manipulación y visualización de datos, procesamiento de imágenes, reducción de dimensionalidad y evaluación de modelos. Esta etapa garantiza que el entorno cuente con todas las funcionalidades necesarias antes de iniciar el procesamiento."
      ],
      "metadata": {
        "id": "jih2JVx1ea5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instalo  itables solo si no esta instalado\n",
        "!pip show itables >/dev/null || pip install itables"
      ],
      "metadata": {
        "id": "y2X7rl9jUe_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from typing import List, Tuple, Dict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# PROYECTO_DIR = \"/content/drive/MyDrive/DMA_Eigenfaces\"\n",
        "# SRC_DIR = os.path.join(PROYECTO_DIR, \"src\")\n",
        "# MODELOS_DIR = os.path.join(PROYECTO_DIR, \"modelos\")\n",
        "\n",
        "#sys.path.append(SRC_DIR)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/src/procesar_imagenes.py\n",
        "!wget https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/src/multiperceptron.py\n",
        "\n",
        "from procesar_imagenes import detectar_cara_dnn, cargar_face_detector, procesar_y_crear_dataset\n",
        "from multiperceptron import multiperceptron\n"
      ],
      "metadata": {
        "id": "ZLjB1-bhceBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Crear directorio para cargar las imágenes**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ei6PpQuGrRZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar las fotos nuevas, se creara una carpeta en el entorno de ejecución de colab en la que se podrán arrastrar o subir las imagenes."
      ],
      "metadata": {
        "id": "93h_xlPArXcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_fotos = \"/content/fotos_nuevas\"\n",
        "\n",
        "os.makedirs(ruta_fotos, exist_ok=True)"
      ],
      "metadata": {
        "id": "Hkj6uk1crsbK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Función para procesar imágenes nuevas**"
      ],
      "metadata": {
        "id": "DyP1tyuiOZpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def procesar_imagenes_nuevas(\n",
        "    input_folder: str,\n",
        "    net: cv2.dnn_Net,\n",
        "    img_size: Tuple[int, int] = (64, 64),\n",
        "    confidence_threshold: float = 0.3\n",
        ") -> pl.DataFrame:\n",
        "    \"\"\"\n",
        "    Procesa imágenes nuevas no etiquetadas: detecta la cara, recorta, convierte a gris, resizea,\n",
        "    y arma un DataFrame compatible con la red neuronal entrenada.\n",
        "\n",
        "    Returns:\n",
        "        Polars DataFrame con columnas: 'imagen' (array aplanado) y 'filename' (nombre de archivo)\n",
        "    \"\"\"\n",
        "    imagenes = []\n",
        "    nombres = []\n",
        "\n",
        "    for file in sorted(os.listdir(input_folder)):\n",
        "        if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            continue\n",
        "\n",
        "        path = os.path.join(input_folder, file)\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        box = detectar_cara_dnn(img, net, confidence_threshold)\n",
        "        if box is not None:\n",
        "            x1, y1, x2, y2 = box\n",
        "\n",
        "            # Añadir margen\n",
        "            margin_ratio = 0.2\n",
        "            bw, bh = x2 - x1, y2 - y1\n",
        "            x1 = max(0, x1 - int(bw * margin_ratio))\n",
        "            y1 = max(0, y1 - int(bh * margin_ratio))\n",
        "            x2 = min(img.shape[1], x2 + int(bw * margin_ratio))\n",
        "            y2 = min(img.shape[0], y2 + int(bh * margin_ratio))\n",
        "\n",
        "            face_crop = img[y1:y2, x1:x2]\n",
        "            face_crop = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)\n",
        "            face_crop = cv2.resize(face_crop, img_size)\n",
        "            imagenes.append(face_crop.flatten())\n",
        "            nombres.append(file)\n",
        "\n",
        "    df = pl.DataFrame({\n",
        "        \"filename\": nombres,\n",
        "        **{f\"x{i+1}\": [img[i] for img in imagenes] for i in range(img_size[0] * img_size[1])}\n",
        "    })\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "gTZFbAkZOeGA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Función para graficar las fotos originales con la etiqueta asignada por el modelo**\n"
      ],
      "metadata": {
        "id": "cYM8nj_glwRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mostrar_predicciones_con_imagenes(input_folder, df_resultado, columnas=5):\n",
        "    filas = (len(df_resultado) + columnas - 1) // columnas\n",
        "    plt.figure(figsize=(3 * columnas, 3.5 * filas))\n",
        "\n",
        "    for i, row in enumerate(df_resultado.iter_rows(named=True)):\n",
        "        filepath = os.path.join(input_folder, row[\"filename\"])\n",
        "        img = cv2.imread(filepath)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.subplot(filas, columnas, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'{row[\"pred_final\"]}\\n({row[\"confianza\"]:.2f})', fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_Ty8YMT1Hu5s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cargar objetos scaler e ISOMAP**\n"
      ],
      "metadata": {
        "id": "1-6KQJaYEB_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar el objeto ISOMAP utilizado para la reducción de dimensiones en el dataset original.\n",
        "\n",
        "Descargamos los archivos scaler.pkl e isomap_9_20.pkl en una carpeta llamada modelos, ubicada en el entorno temporal de ejecución de Colab, para luego cargarlos y reutilizarlos en el preprocesamiento de nuevas imágenes."
      ],
      "metadata": {
        "id": "Fb1yQsn4tYOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir carpeta de modelos\n",
        "MODELOS_DIR = \"/content/modelos\"\n",
        "os.makedirs(MODELOS_DIR, exist_ok=True)\n",
        "\n",
        "# Descargar archivos directamente a la carpeta\n",
        "!wget -O $MODELOS_DIR/isomap.pkl https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/modelos/scaler.pkl\n",
        "!wget -O $MODELOS_DIR/isomap.pkl https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/modelos/isomap.pkl\n",
        "\n",
        "# Cargar objetos\n",
        "with open(os.path.join(MODELOS_DIR, \"scaler.pkl\"), \"rb\") as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(MODELOS_DIR, \"isomap.pkl\"), \"rb\") as f:\n",
        "    isomap = pickle.load(f)"
      ],
      "metadata": {
        "id": "hCvlAMMqEAS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Descarga de la red entrenda**"
      ],
      "metadata": {
        "id": "KzGuM16Ny53r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar e inicializar el multiperceptron\n",
        "\n",
        "!wget -O $MODELOS_DIR/red.pkl https://raw.githubusercontent.com/bnrey/DMA_g1_nuestras_caras/main/modelos/red.pkl\n",
        "\n",
        "# Cargar la red\n",
        "with open(os.path.join(MODELOS_DIR, \"red.pkl\"), \"rb\") as f:\n",
        "    red = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "nA1ZGltaGzlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inicializamos la red neuronal y cargamos el modelo ya entrado**"
      ],
      "metadata": {
        "id": "kwUz2WvTuRF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inicializacion de la red\n",
        "mp = multiperceptron()\n",
        "mp.cargar_modelo((MODELOS_DIR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCW_dmSXufid",
        "outputId": "cbfc431e-569b-4731-cbe7-6ed347b385b3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170, np.float64(5.520267474042412e-06), np.float64(0.0))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Carga del modelo DNN para detección de rostros y procesamiento de las nuevas imagenes**"
      ],
      "metadata": {
        "id": "76GO9pSdzJLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = cargar_face_detector()\n",
        "\n",
        "df_nuevas = procesar_imagenes_nuevas(ruta_fotos, net)"
      ],
      "metadata": {
        "id": "YGiPwBWPFPkn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creación del dataframe que se utilizará en la red neuronal**"
      ],
      "metadata": {
        "id": "vcozbDQgzjsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Convertir imágenes nuevas a matriz\n",
        "X_nuevas = np.array(df_nuevas.select([f\"x{i+1}\" for i in range(64*64)]))\n",
        "\n",
        "# 2. Escalar con el scaler que guardaste\n",
        "X_nuevas_scaled = scaler.transform(X_nuevas)\n",
        "\n",
        "# 3. Aplicar ISOMAP\n",
        "X_nuevas_iso = isomap.transform(X_nuevas_scaled)\n",
        "\n",
        "# 4. Convertir a DataFrame\n",
        "df_nuevas_reducidas = pl.DataFrame({\n",
        "    **{f\"x{i+1}\": X_nuevas_iso[:, i] for i in range(X_nuevas_iso.shape[1])}\n",
        "})"
      ],
      "metadata": {
        "id": "EGxp01r9DjVj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Añadimos una columna y con valores \"?\" como marcador para indicar que estas imágenes nuevas aún no tienen clase asignada. Ya que la red toma el dataframe con la clase y."
      ],
      "metadata": {
        "id": "m83tfLSa0C56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nuevas_reducidas = df_nuevas_reducidas.with_columns(\n",
        "    pl.Series(\"y\", [\"?\"] * df_nuevas_reducidas.height)\n",
        ")"
      ],
      "metadata": {
        "id": "mUiHjh7BF4MA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Predicción sobre las nuevas fotos**"
      ],
      "metadata": {
        "id": "p54L9N_j0NrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predecir\n",
        "y_pred, y_raw, _ = mp.predecir(df_nuevas_reducidas, campos=[f\"x{i+1}\" for i in range(X_nuevas_iso.shape[1])], clase=\"y\")\n"
      ],
      "metadata": {
        "id": "8IHTohn6DBHZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Filtrado por confianza para detectar intrusos**"
      ],
      "metadata": {
        "id": "_h3c62rU0u6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se calcula la confianza del modelo en cada predicción y se aplica un umbral (0.6).\n",
        "Si la confianza es baja, la imagen se clasifica como “intruso”.\n",
        "Se arma un DataFrame final con el nombre del archivo, la predicción original, la confianza y la predicción ajustada."
      ],
      "metadata": {
        "id": "swzBv9J51QOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculás la confianza\n",
        "confianza_max = [max(vec) for vec in y_raw]\n",
        "\n",
        "# Aplicás el umbral para detectar intrusos\n",
        "umbral = 0.5\n",
        "pred_final = [\"intruso\" if c < umbral else p for c, p in zip(confianza_max, y_pred)]\n",
        "\n",
        "# Armás el DataFrame de resultados\n",
        "df_resultado = pl.DataFrame({\n",
        "    \"filename\": df_nuevas[\"filename\"],\n",
        "    \"pred\": y_pred,\n",
        "    \"confianza\": confianza_max,\n",
        "    \"pred_final\": pred_final\n",
        "})"
      ],
      "metadata": {
        "id": "b3UEn_owFtdM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mostrar_predicciones_con_imagenes(ruta_fotos, df_resultado)"
      ],
      "metadata": {
        "id": "jAOPXVPmH_10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}